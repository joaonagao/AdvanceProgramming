{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Web Scraping through Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages for web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct Web Scraping through Google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the DataFrame with company and description columns\n",
    "df = pd.read_csv(\"/Users/jad/Desktop/company_info_final.csv\")\n",
    "\n",
    "# Load the NAICS_subcategories file\n",
    "naics_subcategories = pd.read_csv(\"/Users/jad/Desktop/NAICS_subcategories.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the first 3 digits of the NAICS code\n",
    "df = pd.merge(df, naics_subcategories, left_on=df[\"NAICS on SoS site\"].astype(str).str[:3], right_on=naics_subcategories[\"NAICS Code\"].astype(str).str[:3], how=\"left\")\n",
    "\n",
    "# Define an empty dictionary to store the results\n",
    "keyword_dict = {}\n",
    "\n",
    "# Add the following columns to the DataFrame\n",
    "df[\"keyword_count\"] = 0\n",
    "df[\"found_count\"] = 0\n",
    "df[\"Food\"] = 0\n",
    "df[\"Beverage\"] = 0\n",
    "df[\"Tobacco\"] = 0\n",
    "df[\"Mills\"] = 0\n",
    "df[\"Textile\"] = 0\n",
    "df[\"Apparel\"] = 0\n",
    "df[\"Leather\"] = 0\n",
    "df[\"Footwear\"] = 0\n",
    "df[\"Wood\"] = 0\n",
    "df[\"Paper\"] = 0\n",
    "df[\"Printing\"] = 0\n",
    "df[\"Petroleum\"] = 0\n",
    "df[\"Coal\"] = 0\n",
    "df[\"Chemicals\"] = 0\n",
    "df[\"Plastics\"] = 0\n",
    "df[\"Rubber\"] = 0\n",
    "df[\"Mineral\"] = 0\n",
    "df[\"Metal\"] = 0\n",
    "df[\"Machinery\"] = 0\n",
    "df[\"Electronic\"] = 0\n",
    "df[\"Electrical\"] = 0\n",
    "df[\"Transportation\"] = 0\n",
    "df[\"Furniture\"] = 0\n",
    "df[\"Medical\"] = 0\n",
    "\n",
    "# Add a \"Manufacturing\" column to the DataFrame and set it to False\n",
    "df[\"Manufacturing\"] = False\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define a set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add a \"Website URL\" column to the DataFrame\n",
    "df[\"Website URL\"] = \"\"\n",
    "\n",
    "# Loop through all rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Check if the NAICS Code is blank\n",
    "    if pd.isnull(row[\"NAICS on SoS site\"]):\n",
    "        continue  # skip to next row\n",
    "    \n",
    "    company = row[\"Company\"].strip()\n",
    "    description = row[\"Description\"]\n",
    "    \n",
    "    company_name = company.replace(\"&\", \"and\")\n",
    "        \n",
    "    # Navigate to Google.com with the search query\n",
    "    driver.get(\"https://www.yellowpages.com/\" + company_name + \" \" + \"manufacturing\" + \" \" + \"Rhode Island\")\n",
    "        \n",
    "    # Wait for the search results to load\n",
    "    driver.implicitly_wait(10)\n",
    "        \n",
    "    # Find the first search result link that is not an advertisement\n",
    "    search_results = driver.find_elements('css selector', \"div.tF2Cxc\")\n",
    "    for result in search_results:\n",
    "        try:\n",
    "            search_link = result.find_element('tag name', 'a')\n",
    "            if 'http' in search_link.get_attribute('href') and 'google' not in search_link.get_attribute('href'):\n",
    "                url = search_link.get_attribute('href')\n",
    "                df.at[index, 'Website URL'] = url\n",
    "                search_link.click()\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Wait for the resulting page to load\n",
    "    driver.implicitly_wait(10)\n",
    "        \n",
    "    # Get the webpage content\n",
    "    webpage = driver.page_source\n",
    "        \n",
    "    # Loop through each keyword for the current company\n",
    "    if pd.isnull(description):\n",
    "        continue  # skip to next row\n",
    "    for word in description.split():        \n",
    "        if word.lower() not in stop_words:\n",
    "            keyword_dict.setdefault(word.lower(), []).append(1 if word.lower() in webpage.lower() else 0)\n",
    "            # Increment the found count for the current row if the keyword is found in the webpage\n",
    "            df.at[index, \"found_count\"] += 1 if word.lower() in webpage.lower() else 0\n",
    "            # Increment the keyword count for the current row\n",
    "            df.at[index, \"keyword_count\"] += 1\n",
    "            # Set the value of the industry column to 1 if the word is found in the webpage\n",
    "            if word.lower() == \"food\":\n",
    "                df.at[index, \"Food\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"beverage\":\n",
    "                df.at[index, \"Beverage\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"tobacco\":\n",
    "                df.at[index, \"Tobacco\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"mills\":\n",
    "                df.at[index, \"Mills\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"textile\":\n",
    "                df.at[index, \"Textile\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"apparel\":\n",
    "                df.at[index, \"Apparel\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"leather\":\n",
    "                df.at[index, \"Leather\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"footwear\":\n",
    "                df.at[index, \"Footwear\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"wood\":\n",
    "                df.at[index, \"Wood\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"paper\":\n",
    "                df.at[index, \"Paper\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"printing\":\n",
    "                df.at[index, \"Printing\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"petroleum\":\n",
    "                df.at[index, \"Petroleum\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"coal\":\n",
    "                df.at[index, \"Coal\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"chemicals\":\n",
    "                df.at[index, \"Chemicals\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"plastics\":\n",
    "                df.at[index, \"Plastics\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"rubber\":\n",
    "                df.at[index, \"Rubber\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"mineral\":\n",
    "                df.at[index, \"Mineral\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"metal\":\n",
    "                df.at[index, \"Metal\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"machinery\":\n",
    "                df.at[index, \"Machinery\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"electronic\":\n",
    "                df.at[index, \"Electronic\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"electrical\":\n",
    "                df.at[index, \"Electrical\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"transportation\":\n",
    "                df.at[index, \"Transportation\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"furniture\":\n",
    "                df.at[index, \"Furniture\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"medical\":\n",
    "                df.at[index, \"Medical\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "            elif word.lower() == \"manufacturing\":\n",
    "                df.at[index, \"Manufacturing\"] = 1 if word.lower() in webpage.lower() else 0\n",
    "        else:\n",
    "            keyword_dict.setdefault(word.lower(), []).append(0)\n",
    "    \n",
    "    # Add the found count to the DataFrame\n",
    "    df.at[index, \"found_count\"] = df.at[index, \"found_count\"]\n",
    "    df.at[index, \"Manufacturing\"] = df.at[index, \"Manufacturing\"]\n",
    "        \n",
    "    # Calculate the percentage of keywords found and add to the DataFrame\n",
    "    percentage = df.at[index, \"found_count\"] / df.at[index, \"keyword_count\"] * 100 if df.at[index, \"keyword_count\"] > 0 else 0\n",
    "    df.at[index, \"found_percentage\"] = \"{:.2f}%\".format(percentage)\n",
    "        \n",
    "# Close the web driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Excel file and place it in the \"Web Scrape\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(\"Web Scrape\"):\n",
    "    os.makedirs(\"Web Scrape\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file in the Web Scrape folder\n",
    "df.to_csv(\"Web Scrape/google_web_scrape.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
